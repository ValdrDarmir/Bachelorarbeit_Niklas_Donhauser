{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70220c9c-6357-45d6-987f-3977c59d45fd",
   "metadata": {},
   "source": [
    "# GBERT \n",
    "Name: Niklas Donhauser\n",
    "\n",
    "**Source**\n",
    "\n",
    "[1] sklearn https://scikit-learn.org/stable/ <br>\n",
    "[2] re https://docs.python.org/3/library/re.html <br>\n",
    "[3] pandas https://pandas.pydata.org/ <br>\n",
    "[4] time https://docs.python.org/3/library/time.html <br>\n",
    "[5] numpy https://numpy.org/ <br>\n",
    "[6] Simple Transformers https://simpletransformers.ai/ <br>\n",
    "\n",
    "**Useful links:**\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html <br>\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html <br>\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f515ed6-05bb-46d2-aa13-e3c2c4a4cb95",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9032f26b-6913-4350-81a8-7cb28b6cae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import numpy as np\n",
    "import re\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b7bfa-7c30-4743-b1fa-9850a30e82aa",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9fb1c6-40f8-451c-850c-c4cc53ce2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data):\n",
    "    global train_index, test_index\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=2)\n",
    "    iteration=0\n",
    "    \n",
    "    for train_index, test_index in skf.split(data,data[\"labels\"]):\n",
    "  \n",
    "        iteration=iteration+1\n",
    "        startTime=time.time()\n",
    "        x_train, x_test, y_train, y_test=data.text.values[train_index],data.text.values[test_index],data.labels.values[train_index],data.labels.values[test_index]\n",
    "        training_Df=pd.DataFrame({\"labels\":y_train,\"text\":x_train},columns=[\"text\",\"labels\"])\n",
    "        test_Df=pd.DataFrame({\"labels\":y_test,\"text\":x_test},columns=[\"text\",\"labels\"])\n",
    "\n",
    "        trainModel(training_Df)\n",
    "        predictModel(test_Df,x_train,x_test,y_train,y_test,startTime,iteration)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493b190-f313-4d94-8eab-645c7c15d444",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3346fd-1d3f-4af5-968d-039ce5651e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(training_Df):\n",
    "    global model\n",
    "    print(\"Training Model Now\")\n",
    "    print(training_Df)\n",
    "    train_args ={\"reprocess_input_data\": True,\n",
    "             \"fp16\":False,\n",
    "             \"num_train_epochs\": 4,\n",
    "             \"overwrite_output_dir\":True,\n",
    "             \"train_batch_size\": 32, \n",
    "             \"eval_batch_size\": 32,\n",
    "             \"use_multiprocessing\":False,\n",
    "             \"use_multiprocessing_for_evaluation\":False,\n",
    "             \"no_save\":True} \n",
    "    \n",
    "    model=ClassificationModel('bert', 'deepset/gbert-large', num_labels=2, use_cuda=True, args=train_args)\n",
    "    \n",
    "    \n",
    "    model.train_model(training_Df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee72fe-13d8-419c-8890-48f1854d07b0",
   "metadata": {},
   "source": [
    "## Predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bc3562-ff71-4f2a-9025-5945314f99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictModel(test_Df,x_train,x_test,y_train,y_test,startTime,iteration):\n",
    "    def p_multiclass(labels, preds):\n",
    "        #print(\"Labels: \", labels)\n",
    "        #print(\"Preds: \", preds)\n",
    "        return preds\n",
    "    result, model_outputs, wrong_predictions=model.eval_model(test_Df,acc=accuracy_score,precision=p_multiclass)\n",
    "    \n",
    "    getData(result[\"precision\"],y_train,y_test,startTime,iteration)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324b3e6-cdd7-4c6a-b0f1-bba586079d88",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dad88f6-c5bb-403b-ace3-3895fcaa9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(test_set,y_train,y_test,startTime,iteration):\n",
    "   \n",
    "    corporaType=\"\"\n",
    "    shortcut=\"\"\n",
    "    name=\"\"\n",
    "    totalTextUnits=0\n",
    "    totalTestUnits=0\n",
    "    totalTrainUnits=0\n",
    "    accuracy=0\n",
    "    f1_macro=0\n",
    "    precision_macro=0\n",
    "    recall_macro=0\n",
    "    f1_micro=0\n",
    "    precision_micro=0\n",
    "    recall_micro=0\n",
    "    matrix=[]\n",
    "    f1_binary=0\n",
    "    precision_binary=0\n",
    "    recall_binary=0\n",
    "\n",
    "    splitString=re.split(\"_|/\",file)\n",
    "    corporaType=splitString[8]\n",
    "    shortcut=splitString[9] \n",
    "    name=splitString[10]\n",
    "\n",
    "    totalTime=time.time()-startTime\n",
    "\n",
    "    totalTextUnits=len(data.index)\n",
    "    totalTestUnits=len(test_set)\n",
    "    totalTrainUnits=len(y_train)\n",
    "\n",
    "    accuracy=accuracy_score(y_test, test_set)\n",
    "    \n",
    "    f1_binary=f1_score(y_test, test_set, average=\"binary\",pos_label=0)\n",
    "    precision_binary=precision_score(y_test, test_set, average=\"binary\",pos_label=0)\n",
    "    recall_binary=recall_score(y_test, test_set, average=\"binary\",pos_label=0)\n",
    "        \n",
    "    matrix=confusion_matrix(y_test, test_set, labels=[1,0])\n",
    "        \n",
    "    matrixFlat=convertMatrix(matrix)\n",
    "    target_names = [0,1]\n",
    "    classificationReport=classification_report(y_test, test_set, target_names=target_names, output_dict=True)\n",
    "    saveData(corporaType,shortcut,name,totalTime,totalTextUnits,totalTestUnits,totalTrainUnits,accuracy,f1_macro,precision_macro,recall_macro,f1_micro,precision_micro,recall_micro,matrix,f1_binary,precision_binary,recall_binary,y_test,test_set,startTime,iteration,matrixFlat,classificationReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea6968-699d-457f-8a7c-dbeaa0ac5b78",
   "metadata": {},
   "source": [
    "## Transform confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d773e252-3678-43d0-9629-45eb9e154167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMatrix(matrix):\n",
    "    global flatMatrix\n",
    "    array=[]\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[i])):\n",
    "            array.append(matrix[i][j])\n",
    "    flatMatrix = np.array(array)\n",
    "    return flatMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89680769-61db-44f2-9257-86ca4bba403f",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a9a5af-0bb1-451b-a519-7cdc5e6f6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(corporaType,shortcut,name,totalTime,totalTextUnits,totalTestUnits,totalTrainUnits,accuracy,f1_macro,precision_macro,recall_macro,f1_micro,precision_micro,recall_micro,matrix,f1_binary,precision_binary,recall_binary,y_test,test_set,startTime,iteration, matrixFlat,classificationReport):\n",
    "    df_svm_data=pd.read_csv(\"GBertLargeDataKFold.tsv\", sep=\"\\t\")\n",
    "    df_svm_data_full=pd.read_csv(\"GBertLargeDataKFoldFull.tsv\", sep=\"\\t\")\n",
    "\n",
    "    allData={\"Iteration\":iteration,\"Shortcut\":shortcut,\"Name\":name,\"Type\":corporaType,\"Time\":totalTime,\"Total Length\":totalTextUnits,\"Training Set\":totalTrainUnits,\"Test Set\":totalTestUnits,\"Accuracy\":accuracy,\"Precision Macro\":precision_macro,\n",
    "             \"Precision Micro\":precision_micro,\"Precision Binary\":precision_binary,\"Recall Macro\":recall_macro,\"Recall Micro\":recall_micro,\"Recall Binary\":recall_binary,\"F1 Macro\":f1_macro,\n",
    "            \"F1 Micro\":f1_micro,\"F1 Binary\":f1_binary,\"Matrix\":matrixFlat}\n",
    "\n",
    "    allDataFull={\"Iteration\":iteration,\"Shortcut\":shortcut,\"Name\":name,\"Type\":corporaType,\"Time\":totalTime,\"Total Length\":totalTextUnits,\"Training Set\":totalTrainUnits,\"Test Set\":totalTestUnits,\"Accuracy\":accuracy,\"Precision Macro\":precision_macro,\n",
    "             \"Precision Micro\":precision_micro,\"Precision Binary\":precision_binary,\"Recall Macro\":recall_macro,\"Recall Micro\":recall_micro,\"Recall Binary\":recall_binary,\"F1 Macro\":f1_macro,\n",
    "            \"F1 Micro\":f1_micro,\"F1 Binary\":f1_binary,\"Matrix\":matrixFlat,\"Train Set Full\":y_test,\"Test Set Full\":test_set}\n",
    "\n",
    "    \n",
    "    reportDict=transformReport(classificationReport)\n",
    "    allData.update(reportDict)\n",
    "    allDataFull.update(reportDict)\n",
    "    df_new_data=pd.DataFrame([allData])\n",
    "    df_new_data_full=pd.DataFrame([allDataFull])\n",
    "\n",
    "    finalData_svm=pd.concat([df_svm_data,df_new_data])\n",
    "    finalData_svm_full=pd.concat([df_svm_data_full,df_new_data_full])\n",
    "    \n",
    "    finalData_svm=finalData_svm[[\"Iteration\",\"Shortcut\",\"Name\",\"Type\",\"Time\",\"Total Length\",\"Training Set\",\"Test Set\",\"Accuracy\",\"Precision Macro\",\n",
    "              \"Precision Micro\",\"Precision Binary\",\"Recall Macro\",\"Recall Micro\",\"Recall Binary\",\"F1 Macro\",\n",
    "            \"F1 Micro\",\"F1 Binary\",\"Matrix\",\"0 precision\",\"0 recall\",\"0 f1-score\",\n",
    "            \"0 support\",\"1 precision\",\"1 recall\",\"1 f1-score\",\"1 support\",\"accuracy accuracy\",\n",
    "            \"macro avg precision\",\"macro avg recall\",\"macro avg f1-score\",\"macro avg support\",\"weighted avg precision\",\"weighted avg recall\",\n",
    "            \"weighted avg f1-score\",\"weighted avg support\"]]\n",
    "\n",
    "    finalData_svm_full=finalData_svm_full[[\"Iteration\",\"Shortcut\",\"Name\",\"Type\",\"Time\",\"Total Length\",\"Training Set\",\"Test Set\",\"Accuracy\",\"Precision Macro\",\n",
    "              \"Precision Micro\",\"Precision Binary\",\"Recall Macro\",\"Recall Micro\",\"Recall Binary\",\"F1 Macro\",\n",
    "            \"F1 Micro\",\"F1 Binary\",\"Matrix\",\"Train Set Full\",\"Test Set Full\",\"0 precision\",\"0 recall\",\"0 f1-score\",\n",
    "            \"0 support\",\"1 precision\",\"1 recall\",\"1 f1-score\",\"1 support\",\"accuracy accuracy\",\n",
    "            \"macro avg precision\",\"macro avg recall\",\"macro avg f1-score\",\"macro avg support\",\"weighted avg precision\",\"weighted avg recall\",\n",
    "            \"weighted avg f1-score\",\"weighted avg support\"]]\n",
    "    \n",
    "    finalData_svm.to_csv(\"GBertLargeDataKFold.tsv\", sep=\"\\t\",index=False)\n",
    "    finalData_svm_full.to_csv(\"GBertLargeDataKFoldFull.tsv\", sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9dca85-6bef-4e89-b71c-672517536a78",
   "metadata": {},
   "source": [
    "## Transform classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f0d70f-981f-4ece-96a2-c4de40a5bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformReport(classificationReport):\n",
    "    print(classificationReport)\n",
    "    newDict={}\n",
    "    for key in classificationReport.keys():\n",
    "        mainName=str(key)\n",
    "        if type(classificationReport[key]) != dict:\n",
    "            name=mainName+\" \"+key\n",
    "            newDict[name]=classificationReport[key]\n",
    "            \n",
    "        if type(classificationReport[key]) == dict:\n",
    "            for k in classificationReport[key].keys():\n",
    "                name=mainName+\" \"+k\n",
    "                newDict[name]=classificationReport[key][k]\n",
    "\n",
    "    print(\"DICT:\",newDict)\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4e1f6-b149-45a1-9648-d4e7f524c2da",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d17001-cd74-4385-b286-4ad936c99d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start for corpora:  ../../../Corpora/Preprocessed_Transformers_No_Preprocessing/Binary/SM04_gertwittersent_Preprocessed_binary_Transformer.tsv\n",
      "[ 1  2  3  4  5  6  7  8  9 12 14 15 16 17 18 19 21 23 24 25 27 28 29 30\n",
      " 31 32 33 34 35 37]\n",
      "---------------------------\n",
      "[ 0  4  5  6  8  9 10 11 12 13 15 16 18 19 20 21 22 23 24 25 26 27 28 30\n",
      " 32 33 34 35 36 37]\n",
      "---------------------------\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 13 14 15 17 18 20 22 24 26 27 28 29 30\n",
      " 31 32 33 36 37 42]\n",
      "---------------------------\n",
      "4ter:\n",
      "[ 0  1  2  3  5  7 10 11 12 13 14 16 17 19 20 21 22 23 25 26 29 31 34 35\n",
      " 36 38 39 40 41 43]\n",
      "Training Model Now\n",
      "                                                    text  labels\n",
      "0      @TuT_Parody so einen Rasen hätte sich Hoeneß d...       1\n",
      "1                          @kopfding Pass bloß auf!!! ;)       0\n",
      "2      @kopfding @Stephan535 Es gibt nichts antikeres...       1\n",
      "3      Abstiegsangst! - Kind will mit Korkut sprechen...       1\n",
      "4                  @kopfding @KleinePfeife @tob1i Nacht!       0\n",
      "...                                                  ...     ...\n",
      "21098  RT @titandruecker: Erst das Spiel seiner Trupp...       1\n",
      "21099                   Wind und Rock = keine gute Kombi       1\n",
      "21100  Bitte beachten Sie auch weiterhin die Einschrä...       1\n",
      "21101  @MartinKalus Ich weiß, leider, aber das ist sc...       1\n",
      "21102  3/3 Gratulation @LucasSobotka für den Weitblic...       0\n",
      "\n",
      "[21103 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-large were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9369eb7f75064e469f7dc23a334628a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf5cdc900d7463986acf7627b1de614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/660 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b0c1d016c94c0eb602d683b1a60f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/660 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6f20580a0a4d759fb614c4ef5ac616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/660 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138f159b8b0547fb872e31b8c7ec6636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/660 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1c1f619480421ca2e860b54340f8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.7183286977971644, 'tp': 2438, 'tn': 3634, 'fp': 483, 'fn': 479, 'auroc': 0.929714906519445, 'auprc': 0.8932849035631544, 'acc': 0.8632357122547626, 'precision': array([0, 0, 1, ..., 1, 1, 0]), 'eval_loss': 0.5806435945528474}\n",
      "----------------\n",
      "{0: {'precision': 0.8835399951373694, 'recall': 0.88268156424581, 'f1-score': 0.8831105710814096, 'support': 4117}, 1: {'precision': 0.8346456692913385, 'recall': 0.8357901954062393, 'f1-score': 0.8352175402535116, 'support': 2917}, 'accuracy': 0.8632357122547626, 'macro avg': {'precision': 0.859092832214354, 'recall': 0.8592358798260247, 'f1-score': 0.8591640556674606, 'support': 7034}, 'weighted avg': {'precision': 0.8632635168187922, 'recall': 0.8632357122547626, 'f1-score': 0.8632493298353222, 'support': 7034}}\n",
      "DICT: {'0 precision': 0.8835399951373694, '0 recall': 0.88268156424581, '0 f1-score': 0.8831105710814096, '0 support': 4117, '1 precision': 0.8346456692913385, '1 recall': 0.8357901954062393, '1 f1-score': 0.8352175402535116, '1 support': 2917, 'accuracy accuracy': 0.8632357122547626, 'macro avg precision': 0.859092832214354, 'macro avg recall': 0.8592358798260247, 'macro avg f1-score': 0.8591640556674606, 'macro avg support': 7034, 'weighted avg precision': 0.8632635168187922, 'weighted avg recall': 0.8632357122547626, 'weighted avg f1-score': 0.8632493298353222, 'weighted avg support': 7034}\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "filesBinaryTest=[\"../../../Corpora/Preprocessed_Transformers_No_Preprocessing/Binary/SM04_gertwittersent_Preprocessed_binary_Transformer.tsv\"]\n",
    "\n",
    "def main():\n",
    "    global data, file\n",
    "    for file in filesBinaryTest:\n",
    "        print(\"Start for corpora: \",file)\n",
    "        data=pd.read_csv(file, sep=\"\\t\")\n",
    "        #updateFile(data)\n",
    "        splitData(data)\n",
    "        #print(data)\n",
    "        print(\"Finish\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5187928-6b4f-40d0-a9f6-08f21f0b56af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
