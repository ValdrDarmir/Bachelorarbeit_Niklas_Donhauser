{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70220c9c-6357-45d6-987f-3977c59d45fd",
   "metadata": {},
   "source": [
    "# GELECTRA \n",
    "Name: Niklas Donhauser\n",
    "\n",
    "**Source**\n",
    "\n",
    "[1] sklearn https://scikit-learn.org/stable/ <br>\n",
    "[2] re https://docs.python.org/3/library/re.html <br>\n",
    "[3] pandas https://pandas.pydata.org/ <br>\n",
    "[4] time https://docs.python.org/3/library/time.html <br>\n",
    "[5] numpy https://numpy.org/ <br>\n",
    "[6] Simple Transformers https://simpletransformers.ai/ <br>\n",
    "\n",
    "**Useful links:**\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html <br>\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html <br>\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644a2bf-55e2-4a11-be79-423d77c5810b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9032f26b-6913-4350-81a8-7cb28b6cae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import numpy as np\n",
    "import re\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd71a8d-80de-4ca6-8244-b4108a549051",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9fb1c6-40f8-451c-850c-c4cc53ce2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data):\n",
    "    global train_index, test_index\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=2)\n",
    "    iteration=0\n",
    "\n",
    "    \n",
    "    for train_index, test_index in skf.split(data,data[\"labels\"]):\n",
    "        iteration=iteration+1\n",
    "        startTime=time.time()\n",
    "        x_train, x_test, y_train, y_test=data.text.values[train_index],data.text.values[test_index],data.labels.values[train_index],data.labels.values[test_index]\n",
    "        training_Df=pd.DataFrame({\"labels\":y_train,\"text\":x_train},columns=[\"text\",\"labels\"])\n",
    "        test_Df=pd.DataFrame({\"labels\":y_test,\"text\":x_test},columns=[\"text\",\"labels\"])\n",
    "\n",
    "        trainModel(training_Df)\n",
    "        predictModel(test_Df,x_train,x_test,y_train,y_test,startTime,iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5855d4a6-a758-412f-a4c6-f2b349c5f8c4",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3346fd-1d3f-4af5-968d-039ce5651e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(training_Df):\n",
    "    global model\n",
    "    print(\"Training Model Now\")\n",
    "    print(training_Df)\n",
    "    train_args ={\"reprocess_input_data\": True,\n",
    "             \"fp16\":False,\n",
    "             \"num_train_epochs\": 4,\n",
    "             \"overwrite_output_dir\":True,\n",
    "             \"train_batch_size\": 32, \n",
    "             \"eval_batch_size\": 32,\n",
    "             \"use_multiprocessing\":False,\n",
    "             \"use_multiprocessing_for_evaluation\":False,\n",
    "             \"no_save\":True} \n",
    "    \n",
    "    model=ClassificationModel('electra', 'deepset/gelectra-large', num_labels=3, use_cuda=True, args=train_args)\n",
    "    \n",
    "    model.train_model(training_Df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8db621-e5cd-4d0a-b066-883400198c49",
   "metadata": {},
   "source": [
    "## Predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bc3562-ff71-4f2a-9025-5945314f99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictModel(test_Df,x_train,x_test,y_train,y_test,startTime,iteration):\n",
    "\n",
    "    def p_multiclass(labels, preds):\n",
    "        #print(\"Labels: \", labels)\n",
    "        #print(\"Preds: \", preds)\n",
    "        return preds\n",
    "    result, model_outputs, wrong_predictions=model.eval_model(test_Df,acc=accuracy_score,precision=p_multiclass)\n",
    "    \n",
    "\n",
    "    getData(result[\"precision\"],y_train,y_test,startTime,iteration)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92102c39-e219-42ce-bf74-cd07d163a597",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dad88f6-c5bb-403b-ace3-3895fcaa9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(test_set,y_train,y_test,startTime,iteration):\n",
    "   \n",
    "    corporaType=\"\"\n",
    "    shortcut=\"\"\n",
    "    name=\"\"\n",
    "    totalTextUnits=0\n",
    "    totalTestUnits=0\n",
    "    totalTrainUnits=0\n",
    "    accuracy=0\n",
    "    f1_macro=0\n",
    "    precision_macro=0\n",
    "    recall_macro=0\n",
    "    f1_micro=0\n",
    "    precision_micro=0\n",
    "    recall_micro=0\n",
    "    matrix=[]\n",
    "    f1_binary=0\n",
    "    precision_binary=0\n",
    "    recall_binary=0\n",
    "\n",
    "    splitString=re.split(\"_|/\",file)\n",
    "    corporaType=splitString[8]\n",
    "    shortcut=splitString[9]\n",
    "    name=splitString[10]\n",
    "\n",
    "    totalTime=time.time()-startTime\n",
    "\n",
    "    totalTextUnits=len(data.index)\n",
    "    totalTestUnits=len(test_set)\n",
    "    totalTrainUnits=len(y_train)\n",
    "\n",
    "    accuracy=accuracy_score(y_test, test_set)\n",
    "    \n",
    "    \n",
    "    f1_macro=f1_score(y_test, test_set, average=\"macro\", labels=[1,0,2])\n",
    "    precision_macro=precision_score(y_test, test_set, average=\"macro\", labels=[1,0,2])\n",
    "    recall_macro=recall_score(y_test, test_set, average=\"macro\", labels=[1,0,2])\n",
    "\n",
    "    f1_micro=f1_score(y_test, test_set, average=\"micro\")\n",
    "    precision_micro=precision_score(y_test, test_set, average=\"micro\", labels=[1,0,2])\n",
    "    recall_micro=recall_score(y_test, test_set, average=\"micro\", labels=[1,0,2])\n",
    "\n",
    "    matrix=confusion_matrix(y_test, test_set, labels=[1,0,2])\n",
    "\n",
    "        \n",
    "    matrixFlat=convertMatrix(matrix)\n",
    "    target_names = [0,1,2]\n",
    "    classificationReport=classification_report(y_test, test_set, target_names=target_names, output_dict=True)\n",
    "    saveData(corporaType,shortcut,name,totalTime,totalTextUnits,totalTestUnits,totalTrainUnits,accuracy,f1_macro,precision_macro,recall_macro,f1_micro,precision_micro,recall_micro,matrix,f1_binary,precision_binary,recall_binary,y_test,test_set,startTime,iteration,matrixFlat,classificationReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe1a9f-ded1-4d68-8565-0757d0fd4aaf",
   "metadata": {},
   "source": [
    "## Transform confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d773e252-3678-43d0-9629-45eb9e154167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMatrix(matrix):\n",
    "    global flatMatrix\n",
    "    array=[]\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[i])):\n",
    "            array.append(matrix[i][j])\n",
    "    flatMatrix = np.array(array)\n",
    "    return flatMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e28aa1-33f4-460b-9084-0ebabfc004b2",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a9a5af-0bb1-451b-a519-7cdc5e6f6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(corporaType,shortcut,name,totalTime,totalTextUnits,totalTestUnits,totalTrainUnits,accuracy,f1_macro,precision_macro,recall_macro,f1_micro,precision_micro,recall_micro,matrix,f1_binary,precision_binary,recall_binary,y_test,test_set,startTime,iteration, matrixFlat,classificationReport):\n",
    "    #print(matrixFlat)\n",
    "    df_svm_data=pd.read_csv(\"GElectraDataKFold.tsv\", sep=\"\\t\")\n",
    "    df_svm_data_full=pd.read_csv(\"GElectraDataKFoldFull.tsv\", sep=\"\\t\")\n",
    "\n",
    "    allData={\"Iteration\":iteration,\"Shortcut\":shortcut,\"Name\":name,\"Type\":corporaType,\"Time\":totalTime,\"Total Length\":totalTextUnits,\"Training Set\":totalTrainUnits,\"Test Set\":totalTestUnits,\"Accuracy\":accuracy,\"Precision Macro\":precision_macro,\n",
    "             \"Precision Micro\":precision_micro,\"Precision Binary\":precision_binary,\"Recall Macro\":recall_macro,\"Recall Micro\":recall_micro,\"Recall Binary\":recall_binary,\"F1 Macro\":f1_macro,\n",
    "            \"F1 Micro\":f1_micro,\"F1 Binary\":f1_binary,\"Matrix\":matrixFlat}\n",
    "\n",
    "    allDataFull={\"Iteration\":iteration,\"Shortcut\":shortcut,\"Name\":name,\"Type\":corporaType,\"Time\":totalTime,\"Total Length\":totalTextUnits,\"Training Set\":totalTrainUnits,\"Test Set\":totalTestUnits,\"Accuracy\":accuracy,\"Precision Macro\":precision_macro,\n",
    "             \"Precision Micro\":precision_micro,\"Precision Binary\":precision_binary,\"Recall Macro\":recall_macro,\"Recall Micro\":recall_micro,\"Recall Binary\":recall_binary,\"F1 Macro\":f1_macro,\n",
    "            \"F1 Micro\":f1_micro,\"F1 Binary\":f1_binary,\"Matrix\":matrixFlat,\"Train Set Full\":y_test,\"Test Set Full\":test_set}\n",
    "\n",
    "    \n",
    "    reportDict=transformReport(classificationReport)\n",
    "    allData.update(reportDict)\n",
    "    allDataFull.update(reportDict)\n",
    "    df_new_data=pd.DataFrame([allData])\n",
    "    df_new_data_full=pd.DataFrame([allDataFull])\n",
    "\n",
    "    finalData_svm=pd.concat([df_svm_data,df_new_data])\n",
    "    finalData_svm_full=pd.concat([df_svm_data_full,df_new_data_full])\n",
    "    \n",
    "    finalData_svm=finalData_svm[[\"Iteration\",\"Shortcut\",\"Name\",\"Type\",\"Time\",\"Total Length\",\"Training Set\",\"Test Set\",\"Accuracy\",\"Precision Macro\",\n",
    "              \"Precision Micro\",\"Precision Binary\",\"Recall Macro\",\"Recall Micro\",\"Recall Binary\",\"F1 Macro\",\n",
    "            \"F1 Micro\",\"F1 Binary\",\"Matrix\",\"0 precision\",\"0 recall\",\"0 f1-score\",\n",
    "            \"0 support\",\"1 precision\",\"1 recall\",\"1 f1-score\",\"1 support\",\"2 f1-score\",\"2 support\",\"2 precision\",\"2 recall\",\"accuracy accuracy\",\n",
    "            \"macro avg precision\",\"macro avg recall\",\"macro avg f1-score\",\"macro avg support\",\"weighted avg precision\",\"weighted avg recall\",\n",
    "            \"weighted avg f1-score\",\"weighted avg support\"]]\n",
    "\n",
    "    finalData_svm_full=finalData_svm_full[[\"Iteration\",\"Shortcut\",\"Name\",\"Type\",\"Time\",\"Total Length\",\"Training Set\",\"Test Set\",\"Accuracy\",\"Precision Macro\",\n",
    "              \"Precision Micro\",\"Precision Binary\",\"Recall Macro\",\"Recall Micro\",\"Recall Binary\",\"F1 Macro\",\n",
    "            \"F1 Micro\",\"F1 Binary\",\"Matrix\",\"Train Set Full\",\"Test Set Full\",\"0 precision\",\"0 recall\",\"0 f1-score\",\n",
    "            \"0 support\",\"1 precision\",\"1 recall\",\"1 f1-score\",\"1 support\",\"2 f1-score\",\"2 support\",\"2 precision\",\"2 recall\",\"accuracy accuracy\",\n",
    "            \"macro avg precision\",\"macro avg recall\",\"macro avg f1-score\",\"macro avg support\",\"weighted avg precision\",\"weighted avg recall\",\n",
    "            \"weighted avg f1-score\",\"weighted avg support\"]]\n",
    "    \n",
    "    finalData_svm.to_csv(\"GElectraDataKFold.tsv\", sep=\"\\t\",index=False)\n",
    "    finalData_svm_full.to_csv(\"GElectraDataKFoldFull.tsv\", sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9272b-4b19-4473-9e25-1c8592b6e574",
   "metadata": {},
   "source": [
    "## Transform classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f0d70f-981f-4ece-96a2-c4de40a5bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformReport(classificationReport):\n",
    "    newDict={}\n",
    "    for key in classificationReport.keys():\n",
    "        mainName=str(key)\n",
    "        if type(classificationReport[key]) != dict:\n",
    "            name=mainName+\" \"+key\n",
    "            newDict[name]=classificationReport[key]\n",
    "            \n",
    "        if type(classificationReport[key]) == dict:\n",
    "            for k in classificationReport[key].keys():\n",
    "                name=mainName+\" \"+k\n",
    "                newDict[name]=classificationReport[key][k]\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e2996c-1db4-4bd8-b8f4-00872d31f2f2",
   "metadata": {},
   "source": [
    "## main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d17001-cd74-4385-b286-4ad936c99d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start for corpora:  ../../../Corpora/Preprocessed_Transformers_No_Preprocessing/Ternary/SM04_gertwittersent_Preprocessed_ternary_Transformer.tsv\n",
      "[ 3  4  6  7 10 12 13 14 16 17 22 23 24 27 29 31 32 34 36 38 39 40 41 43\n",
      " 44 46 47 48 49 50]\n",
      "---------------------------\n",
      "[ 0  1  2  5  6  8  9 11 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34]\n",
      "---------------------------\n",
      "2 ter\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 18 19 20 21 22 23 25 26\n",
      " 27 28 30 32 33 35]\n",
      "Training Model Now\n",
      "                                                    text  labels\n",
      "0      @TuT_Parody so einen Rasen hätte sich Hoeneß d...       1\n",
      "1      RT @heisec: Apples iCloud verschickt und empfä...       2\n",
      "2                          @kopfding Pass bloß auf!!! ;)       0\n",
      "3      @kopfding @Stephan535 Es gibt nichts antikeres...       1\n",
      "4      Abstiegsangst! - Kind will mit Korkut sprechen...       1\n",
      "...                                                  ...     ...\n",
      "48371  3D Animation: Vettel und Ricciardo erklären de...       2\n",
      "48372  Willst Du Dein Profilbild adaptieren und auf #...       2\n",
      "48373  RT @FAZ_Finanzen: Apple tauscht Netzteile älte...       2\n",
      "48374  3/3 Gratulation @LucasSobotka für den Weitblic...       0\n",
      "48375  Tolle Grafik über den Twitter-Traffic während ...       2\n",
      "\n",
      "[48376 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gelectra-large were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at deepset/gelectra-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96810036e84a439abd083689c0cb825e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4376b1848c98498ca6d9a59918db8d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2b8c9ef69846a09a8fa363d3bd6fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f140ff672c5c48bbbb5e13f8850b19b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9c1953b9624ebc9c19cc35401ba592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.46412179450529084, 'acc': 0.6896744186046512, 'precision': array([0, 2, 0, ..., 2, 2, 2]), 'eval_loss': 1.1207546996218818}\n",
      "----------------\n",
      "{0: {'precision': 0.6090279436350609, 'recall': 0.6193830459072139, 'f1-score': 0.6141618497109825, 'support': 4117}, 1: {'precision': 0.6343963553530751, 'recall': 0.5728488172780254, 'f1-score': 0.6020536840208972, 'support': 2917}, 2: {'precision': 0.7416165090283748, 'recall': 0.7589924100758992, 'f1-score': 0.7502038597444957, 'support': 9091}, 'accuracy': 0.6896744186046512, 'macro avg': {'precision': 0.661680269338837, 'recall': 0.6504080910870461, 'f1-score': 0.6554731311587917, 'support': 16125}, 'weighted avg': {'precision': 0.6883682416178245, 'recall': 0.6896744186046512, 'f1-score': 0.6886696570844206, 'support': 16125}}\n",
      "DICT: {'0 precision': 0.6090279436350609, '0 recall': 0.6193830459072139, '0 f1-score': 0.6141618497109825, '0 support': 4117, '1 precision': 0.6343963553530751, '1 recall': 0.5728488172780254, '1 f1-score': 0.6020536840208972, '1 support': 2917, '2 precision': 0.7416165090283748, '2 recall': 0.7589924100758992, '2 f1-score': 0.7502038597444957, '2 support': 9091, 'accuracy accuracy': 0.6896744186046512, 'macro avg precision': 0.661680269338837, 'macro avg recall': 0.6504080910870461, 'macro avg f1-score': 0.6554731311587917, 'macro avg support': 16125, 'weighted avg precision': 0.6883682416178245, 'weighted avg recall': 0.6896744186046512, 'weighted avg f1-score': 0.6886696570844206, 'weighted avg support': 16125}\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "filesTernaryTest=[\"../../../Corpora/Preprocessed_Transformers_No_Preprocessing/Ternary/SM04_gertwittersent_Preprocessed_ternary_Transformer.tsv\"]\n",
    "\n",
    "def main():\n",
    "    global data, file\n",
    "    for file in filesTernaryTest:\n",
    "        print(\"Start for corpora: \",file)\n",
    "        data=pd.read_csv(file, sep=\"\\t\")\n",
    "        splitData(data)\n",
    "        print(\"Finish\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5187928-6b4f-40d0-a9f6-08f21f0b56af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
