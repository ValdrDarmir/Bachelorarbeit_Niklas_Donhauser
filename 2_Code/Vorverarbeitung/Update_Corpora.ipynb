{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rework and Update Corpora \n",
    "A few functions that helped to update Corpora and correct a few smaller mistakes\n",
    "\n",
    "Name: Niklas Donhauser\n",
    "\n",
    "**Source**\n",
    "\n",
    "[1] random https://docs.python.org/3/library/random.html <br>\n",
    "[2] os https://docs.python.org/3/library/os.html <br>\n",
    "[3] pandas https://pandas.pydata.org/ <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smaller manipulation of a few mistakes in corporas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"../../Corpora/Preprocessed/Ternary/SM02_potts_Preprocessed_ternary.tsv\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "df=df[df[\"sentiment\"].str.contains(\"mixed\")==False]\n",
    "df.to_csv(\"SM02_potts_Preprocessed_ternary.tsv\", sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting different Classes in the corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_Preprocessed_ternary_all.tsv\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "count=df[\"sentiment\"].value_counts()\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Ternary corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ternary=[\"../../Corpora/Preprocessed/Ternary/LT01_gnd_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/LT02_speechLessing_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/LT03_historicplays_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI01_mlsa_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI02_germeval_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI03_corpusRauh_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA01_gersen_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA02_gerom_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA03_ompc_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE01_usage_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE02_scare_Preprocessed_ternary_all.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE03_critics_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE04_filmstarts_Preprocessed_ternary_all.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_Preprocessed_binary_all.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM01_sb10k_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM02_potts_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM03_multiSe_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM04_gertwittersent_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM05_ironycorpus_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM06_celeb_Preprocessed_ternary.tsv\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of RE05, RE02 and RE04, smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"../../Corpora/Preprocessed/Ternary/RE02_scare_0_Preprocessed_ternary.tsv\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "\n",
    "file1=\"../../Corpora/Preprocessed/Ternary/RE02_scare_1_Preprocessed_ternary.tsv\"\n",
    "df1 = pd.read_csv(file1 , sep=\"\\t\")\n",
    "\n",
    "file2=\"../../Corpora/Preprocessed/Ternary/RE02_scare_2_Preprocessed_ternary.tsv\"\n",
    "df2 = pd.read_csv(file2 , sep=\"\\t\")\n",
    "\n",
    "file3=\"../../Corpora/Preprocessed/Ternary/RE02_scare_3_Preprocessed_ternary.tsv\"\n",
    "df3 = pd.read_csv(file3 , sep=\"\\t\")\n",
    "\n",
    "file4=\"../../Corpora/Preprocessed/Ternary/RE02_scare_4_Preprocessed_ternary.tsv\"\n",
    "df4 = pd.read_csv(file4 , sep=\"\\t\")\n",
    "\n",
    "file5=\"../../Corpora/Preprocessed/Ternary/RE02_scare_5_Preprocessed_ternary.tsv\"\n",
    "df5 = pd.read_csv(file5 , sep=\"\\t\")\n",
    "\n",
    "file6=\"../../Corpora/Preprocessed/Ternary/RE02_scare_6_Preprocessed_ternary.tsv\"\n",
    "df6 = pd.read_csv(file6 , sep=\"\\t\")\n",
    "\n",
    "frames = [df, df1, df2, df3, df4, df5, df6]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "result.to_csv(\"RE02_scare_Preprocessed_ternary_all.tsv\", sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"../../Corpora/Preprocessed/Ternary/RE04_filmstarts_0_Preprocessed_ternary.tsv\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "\n",
    "file1=\"../../Corpora/Preprocessed/Ternary/RE04_filmstarts_1_Preprocessed_ternary.tsv\"\n",
    "df1 = pd.read_csv(file1 , sep=\"\\t\")\n",
    "\n",
    "file2=\"../../Corpora/Preprocessed/Ternary/RE04_filmstarts_2_Preprocessed_ternary.tsv\"\n",
    "df2 = pd.read_csv(file2 , sep=\"\\t\")\n",
    "frames = [df, df1, df2]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "result.to_csv(\"RE04_filmstarts_Preprocessed_ternary_all.tsv\", sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_0_Preprocessed_ternary.tsv\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "\n",
    "file1=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_1_Preprocessed_ternary.tsv\"\n",
    "df1 = pd.read_csv(file1 , sep=\"\\t\")\n",
    "\n",
    "file2=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_2_Preprocessed_ternary.tsv\"\n",
    "df2 = pd.read_csv(file2 , sep=\"\\t\")\n",
    "\n",
    "file3=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_3_Preprocessed_ternary.tsv\"\n",
    "df3 = pd.read_csv(file3 , sep=\"\\t\")\n",
    "\n",
    "file4=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_4_Preprocessed_ternary.tsv\"\n",
    "df4 = pd.read_csv(file4 , sep=\"\\t\")\n",
    "\n",
    "file5=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_5_Preprocessed_ternary.tsv\"\n",
    "df5 = pd.read_csv(file5 , sep=\"\\t\")\n",
    "\n",
    "file6=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_6_Preprocessed_ternary.tsv\"\n",
    "df6 = pd.read_csv(file6 , sep=\"\\t\")\n",
    "\n",
    "file7=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_7_Preprocessed_ternary.tsv\"\n",
    "df7 = pd.read_csv(file7 , sep=\"\\t\")\n",
    "\n",
    "file8=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_8_Preprocessed_ternary.tsv\"\n",
    "df8 = pd.read_csv(file8 , sep=\"\\t\")\n",
    "\n",
    "file9=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_9_Preprocessed_ternary.tsv\"\n",
    "df9 = pd.read_csv(file9 , sep=\"\\t\")\n",
    "\n",
    "file10=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_10_Preprocessed_ternary.tsv\"\n",
    "df10 = pd.read_csv(file10 , sep=\"\\t\")\n",
    "\n",
    "file11=\"../../Corpora/Preprocessed/Ternary/RE05_amazonreviews_11_Preprocessed_ternary.tsv\"\n",
    "df11 = pd.read_csv(file11 , sep=\"\\t\")\n",
    "\n",
    "frames = [df, df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "result.to_csv(\"RE05_amazonreviews_Preprocessed_ternary_all.tsv\", sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Big Corpora RE05 and RE02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral    60598\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file=\"../../Corpora/Preprocessed/Ternary/RE02_scare_Preprocessed_ternary_all.tsv\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "df=df[df[\"sentiment\"].str.contains(\"positive\")==False]\n",
    "df=df[df[\"sentiment\"].str.contains(\"negative\")==False]\n",
    "df.to_csv(\"RE02_Neu.tsv\", sep=\"\\t\",index=False)\n",
    "count=df[\"sentiment\"].value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Balanced Supset from Re05 and Re02\n",
    "\n",
    "Re02: 70000 (Binary) 35k zu 35k || 70002(Ternary)  23.334 <br>\n",
    "Re05: 70000 (Binary) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral    23334\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "file=\"RE02_Neu\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "goal=23334\n",
    "count=0\n",
    "\n",
    "list2=[]\n",
    "checkList=[]\n",
    "while count< goal:\n",
    "    random_number = random.randint(1, 60597)\n",
    "    \n",
    "    if random_number not in checkList:\n",
    "        checkList.append(random_number)\n",
    "        count=count+1\n",
    "        #print(df.iloc[random_number])\n",
    "        list2.append(df.iloc[random_number])\n",
    "\n",
    "df2 = pd.DataFrame(list2)\n",
    "count=df2[\"sentiment\"].value_counts()\n",
    "print(count)\n",
    "df2.to_csv(\"RE02_Neu3T.tsv\", sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    23334\n",
      "negative    23334\n",
      "neutral     23334\n",
      "Name: sentiment, dtype: int64\n",
      "0\n",
      "70002\n"
     ]
    }
   ],
   "source": [
    "file=\"RE02_Pos3T.tsv\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "\n",
    "file1=\"RE02_Neg3T.tsv\"\n",
    "df1 = pd.read_csv(file1 , sep=\"\\t\")\n",
    "\n",
    "file2=\"RE02_Neu3T.tsv\"\n",
    "df2 = pd.read_csv(file2 , sep=\"\\t\")\n",
    "\n",
    "frames = [df, df1, df2]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "\n",
    "result.to_csv(\"RE02_scare_Preprocessed_ternary_balanced.tsv\", sep=\"\\t\",index=False)\n",
    "count=result[\"sentiment\"].value_counts()\n",
    "print(count)\n",
    "print(len(result)-len(result.drop_duplicates()))\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"RE05_Pos.tsv\"\n",
    "df = pd.read_csv(file , sep=\"\\t\")\n",
    "count=df[\"sentiment\"].value_counts()\n",
    "print(count)\n",
    "print(len(df)-len(df.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Neutral sentiment -> Corpora now Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ternary=[\"../../Corpora/Preprocessed/Ternary/LT01_gnd_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/LT02_speechLessing_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/LT03_historicplays_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI01_mlsa_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI02_germeval_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI03_corpusRauh_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA01_gersen_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA02_gerom_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA03_ompc_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE01_usage_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE03_critics_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE04_filmstarts_Preprocessed_ternary_all.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM01_sb10k_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM02_potts_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM03_multiSe_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM04_gertwittersent_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM05_ironycorpus_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM06_celeb_Preprocessed_ternary.tsv\",\n",
    "            ]\n",
    "for file in file_ternary:\n",
    "    path,fileName =os.path.split(file)\n",
    "    fileName= re.sub(\"_ternary.tsv\",\"\",fileName)\n",
    "    df = pd.read_csv(file , sep=\"\\t\")\n",
    "    df=df[df[\"sentiment\"].str.contains(\"neutral\")==False]\n",
    "    NewFileName=fileName+\"_binary.tsv\"\n",
    "    print(NewFileName)\n",
    "    count=df[\"sentiment\"].value_counts()\n",
    "    print(count)\n",
    "    print(\"Duplicates:\",len(df)-len(df.drop_duplicates()))\n",
    "    df.to_csv(NewFileName, sep=\"\\t\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "file_ternary=[\"../../Corpora/Preprocessed/Ternary/LT01_gnd_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/LT02_speechLessing_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI01_mlsa_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI02_germeval_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/MI03_corpusRauh_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA01_gersen_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA02_gerom_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/NA03_ompc_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE01_usage_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE02_scare_Preprocessed_ternary_balanced.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE03_critics_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/RE04_filmstarts_Preprocessed_ternary_all.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM01_sb10k_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM02_potts_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM03_multiSe_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM04_gertwittersent_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM05_ironycorpus_Preprocessed_ternary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Ternary/SM06_celeb_Preprocessed_ternary.tsv\"\n",
    "            ]\n",
    "file_ternary_single=[\"../../Corpora/Preprocessed/Ternary/RE02_scare_Preprocessed_ternary_all.tsv\"\n",
    "            ]\n",
    "file_binary=[\"../../Corpora/Preprocessed/Binary/LT01_gnd_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/LT02_speechLessing_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/LT03_historicplays_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/MI01_mlsa_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/MI02_germeval_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/MI03_corpusRauh_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/NA01_gersen_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/NA02_gerom_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/NA03_ompc_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/RE01_usage_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/RE02_scare_Preprocessed_binary_balanced.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/RE03_critics_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/RE05_amazonreviews_Preprocessed_binary_all.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/RE05_amazonreviews_Preprocessed_binary_balanced.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/RE04_filmstarts_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/SM01_sb10k_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/SM02_potts_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/SM03_multiSe_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/SM04_gertwittersent_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/SM05_ironycorpus_Preprocessed_binary.tsv\",\n",
    "            \"../../Corpora/Preprocessed/Binary/SM06_celeb_Preprocessed_binary.tsv\"\n",
    "            ]\n",
    "for file in file_binary:\n",
    "    df = pd.read_csv(file , sep=\"\\t\")\n",
    "    path,fileName =os.path.split(file)\n",
    "    if df['id'].isnull().sum()>0 or df['sentiment'].isnull().sum()>0 or df['preprocessedData'].isnull().sum()>0:\n",
    "        file=\"../../Corpora/Preprocessed/Ternary/RE04_filmstarts_Preprocessed_ternary_all.tsv\"\n",
    "        print(fileName)\n",
    "\n",
    "        count=df[\"sentiment\"].value_counts()\n",
    "        print(count)\n",
    "        print(\"-------------\")\n",
    "        df2=df.dropna(subset=[\"sentiment\",\"preprocessedData\",\"id\"])\n",
    "\n",
    "        print(df['id'].isnull().sum())\n",
    "        print(df['sentiment'].isnull().sum())\n",
    "        print(df['preprocessedData'].isnull().sum())\n",
    "\n",
    "        df2 = df2[df2['preprocessedData'].notna()]\n",
    "        count=df2[\"sentiment\"].value_counts()\n",
    "        print(count)\n",
    "        df2.to_csv(fileName, sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
